{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 400.1 | Prompt Engineering For Developers\n",
    "\n",
    "Notes and exercises based on the [ChatGPT Prompt Engineering For Developers](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/) course from DeepLearning.AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 0. Validate Setup\n",
    "\n",
    "Before you begin working on exercises in this section, make sure you are setup to work with the right LLM Providers by running the relevant code cells from the [LLM Setup](./400-00-llm-setup.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. Introduction \n",
    "\n",
    "This course was created when OpenAI was using version 0.28. In this notebook I hope to use the course for insights, but use it in conjunction with the OpenAI documentation to update the learnings for the latest OpenAI versions and practices. Quick study notes\n",
    "\n",
    "1. LLM = Large Language Model. Understands Natural Language. Takes NLP inputs (prompts), returns NLP outputs (responses).\n",
    "1. 2 types of LLM = Base LLM (predicts next word), Instruction Tuned LLM (follows instructions)\n",
    "1. Base LLM = Default, also referred to as Foundation Models that are trained on large corpora of text data.\n",
    "1. Instruction Tuned LLM = Fine-tuned version of base LLM using RLHF (Reinforcement Learning from Human Feedback) to follow instructions.\n",
    "1. Generative AI Focus = Increasingly on Instruction Tuned LLMs, and using NLP to have AI execute tasks based on instruction prompts.\n",
    "\n",
    "LLMs are smart in the sense of having a massive knowledge base and fast pattern-matching capabilities. But they lack the human cognitive ability to understand context, reason, and infer meaning. Instead, they are effectively reflecting the data they were trained on - which means instruction-tuned LLMs are only as effective as the clarity and specificity of instructions they are given.\n",
    "\n",
    "\n",
    "The course has its own sandbox environment for practice, but I want to try my own experiments here. \n",
    "- Refer to the [Setup notebook](400-00-llm-setup.ipynb) for code snippets for chat completion\n",
    "- Refer to the [OpenAI API documentation](https://platform.openai.com/docs/quickstart?context=python) for quickstarts\n",
    "- Refer to the [OpenAI Cookbook](https://cookbook.openai.com/) for richer examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. Principle 1: Write Clear and Concise Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.0 Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an OpenAI client instance\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# Create a helper function to reuse across exercises\n",
    "# So we can focus on prompt engineering more clearly\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "  messages = [{\"role\": \"user\", \"content\": prompt }]\n",
    "  completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    temperature=0, #degree of randomness\n",
    "  )\n",
    "  return completion.choices[0].message.content\n",
    "\n",
    "# Prompting Principles\n",
    "# 1. Write clear and specific instructions\n",
    "# 2. Give the model time to \"think\"\n",
    "# ====================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Tactic: Delimiters For Contextual Boundaries\n",
    "\n",
    "Give model clear guidance on what it should focus on for the task. Delimiters can also reduce prompt injection attacks by guiding it to focus on the right context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Explore diverse cultures through food\n",
      "- Enjoy sushi in Japan, pasta in Italy\n",
      "- Try paella in Spain, tacos in Mexico\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make sure cells are run in order to have client setup.\n",
    "# The prompt (user or system message) defines delimiter.\n",
    "\n",
    "text = f\"\"\"\n",
    "You should express what you want a model to do by \\ \n",
    "providing instructions that are as clear and \\ \n",
    "specific as you can possibly make them. \\ \n",
    "This will guide the model towards the desired output, \\ \n",
    "and reduce the chances of receiving irrelevant \\ \n",
    "or incorrect responses. Don't confuse writing a \\ \n",
    "clear prompt with writing a short prompt. \\ \n",
    "In many cases, longer prompts provide more clarity \\ \n",
    "and context for the model, which can lead to \\ \n",
    "more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "noise = f\"\"\"\n",
    "Let's talk about amazing food that you can get when \\\n",
    "travel the world and explore different cultures. \\\n",
    "I love sushi in Japan and pasta in Italy. \\\n",
    "I love paella in Spain and tacos in Mexico. \\\n",
    "\"\"\"\n",
    "\n",
    "# Craft Prompt\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple asterisks \\ \n",
    "into 3 bullet points each with under 10 words.\n",
    "{text}***{noise}***\n",
    "\"\"\"\n",
    "\n",
    "# Print Completion \n",
    "print(get_completion(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Tactic: Ask For Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "    {\n",
      "        \"movie_id\": 1,\n",
      "        \"title\": \"The Last Frontier\",\n",
      "        \"description\": \"In a post-apocalyptic world, a group of survivors must navigate through dangerous territories to find a safe haven known as The Last Frontier.\",\n",
      "        \"genre\": \"Action/Adventure\",\n",
      "        \"rating\": \"PG-13\"\n",
      "    },\n",
      "    {\n",
      "        \"movie_id\": 2,\n",
      "        \"title\": \"Echoes of the Past\",\n",
      "        \"description\": \"A detective uncovers a series of murders that seem to be connected to a dark secret from his own past, leading him on a dangerous journey to solve the mystery.\",\n",
      "        \"genre\": \"Mystery/Thriller\",\n",
      "        \"rating\": \"R\"\n",
      "    },\n",
      "    {\n",
      "        \"movie_id\": 3,\n",
      "        \"title\": \"Dreamscape\",\n",
      "        \"description\": \"A young woman discovers she has the ability to enter people's dreams, but soon realizes that her gift comes with a dark side that threatens to consume her.\",\n",
      "        \"genre\": \"Fantasy/Horror\",\n",
      "        \"rating\": \"PG-13\"\n",
      "    }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Craft Prompt\n",
    "prompt = f\"\"\"\n",
    "Generate a list of three imaginary movies \\ \n",
    "with a short teaser description, genre and movie rating. \n",
    "Provide them in JSON format with the following keys: \n",
    "movie_id, title, description, genre, rating.\n",
    "\"\"\"\n",
    "\n",
    "# Print Completion \n",
    "print(get_completion(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Tactic: Ask Model to Check Conditions Met\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First, buy almond flour, an egg, butter, and brown sugar. \n",
      "Then, mix those ingredients in a bowl with salt and baking soda after melting the butter. \n",
      "Then, wrap the dough and refrigerate for an hour. \n",
      "Next, preheat the oven to 350 degrees. \n",
      "Then, remove the dough, flatten it, and cut out rounds. \n",
      "Finally, bake for 10 minutes, let them cool, and enjoy your cookies!\n",
      "-------------\n",
      "Nothing to do!\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "# Primary Content\n",
    "good_text = f\"\"\"\n",
    "To make a good almond cookie you need to buy a pack of almond flour \\\n",
    "and have 1 egg, 1 stick of butter and a cup of brown sugar on hand. \\\n",
    "Get a bowl and mix those ingredients with a pinch of salt and baking \\\n",
    "soda - but make sure you melt the butter first. Then wrap the dough \\\n",
    "and refrigerate for an hour. Preheat the oven to 350 degrees. Remove \\\n",
    "dough, flatten it out and cut out rounds. Bake for 10 minutes. \\ \n",
    "Let them cool and enjoy your cookies!\n",
    "\"\"\"\n",
    "bad_text = f\"\"\"\n",
    "It's a beautiful day outside. The sun is shining, the birds are singing. \\\n",
    "The flowers are blooming. On days like these, I want to bake cookies!\n",
    "\"\"\"\n",
    "\n",
    "# Craft Prompt\n",
    "instruction = f\"\"\"\n",
    "You will be provided with text delimited by four asterisks. \\\n",
    "If that texts contains a sequence of instructions rewrite in steps like: \\\n",
    "\n",
    "- First ... \n",
    "- Then ..\n",
    "- Then ..\n",
    "...\n",
    "- Finally ..\n",
    "\n",
    "Make sure each step has only 1 sentence. Break things down.\n",
    "Use simple conversational language and be clear\n",
    "If text has no instructions write \\\"Nothing to do!\\\"\n",
    "\n",
    "****{good_text}{bad_text}****\n",
    "\"\"\"\n",
    "\n",
    "# Print Completion \n",
    "prompt = f\"\"\"\n",
    "{instruction}****{good_text}****\n",
    "\"\"\"\n",
    "print(get_completion(prompt))\n",
    "print(\"-------------\")\n",
    "\n",
    "# Print Completion \n",
    "prompt = f\"\"\"\n",
    "{instruction}****{bad_text}****\n",
    "\"\"\"\n",
    "print(get_completion(prompt))\n",
    "print(\"-------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Tactic: Few Shot Prompting (by examples)\n",
    "\n",
    "Give examples of what you want model to do and let is figure out what to do, then give it a task to do.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<grandparent>: Resilience is like a tree that bends in the \\ \n",
      "strongest winds but never breaks; it is the \\ \n",
      "ability to bounce back from adversity and \\ \n",
      "continue to grow and thrive despite challenges.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to answer in a consistent style.\n",
    "\n",
    "<child>: Teach me about patience.\n",
    "\n",
    "<grandparent>: The river that carves the deepest \\ \n",
    "valley flows from a modest spring; the \\ \n",
    "grandest symphony originates from a single note; \\ \n",
    "the most intricate tapestry begins with a solitary thread.\n",
    "\n",
    "<child>: Teach me about resilience.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Principle 2: Give the Model Time To Think"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.1 Tactic: Specify steps required (chain of reasoning)\n",
    "\n",
    "Give the model a series of steps it should take before it returns the response. Slow the model down so it puts more time into the computation instead of returning an immediate result. The added effort will improve the quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion 1:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "1 - Jack and Jill go on a quest to fetch water, but misfortune strikes as Jack trips and tumbles down a hill with Jill following suit, yet they return home with comforting embraces and continue exploring with delight.\n",
      "2 - Jack y Jill van en una b√∫squeda para traer agua, pero la desgracia golpea cuando Jack tropieza y cae por una colina con Jill siguiendo el ejemplo, sin embargo, regresan a casa con abrazos reconfortantes y contin√∫an explorando con alegr√≠a.\n",
      "3 - Jack, Jill\n",
      "4 - {\n",
      "    \"spanish_summary\": \"Jack y Jill van en una b√∫squeda para traer agua, pero la desgracia golpea cuando Jack tropieza y cae por una colina con Jill siguiendo el ejemplo, sin embargo, regresan a casa con abrazos reconfortantes y contin√∫an explorando con alegr√≠a.\",\n",
      "    \"num_names\": 2\n",
      "} \n",
      "----\n",
      "Completion 2:\n",
      "Summary: Jack and Jill, siblings, go on a quest to fetch water but encounter misfortune on the way back.\n",
      "\n",
      "Translation: Jack et Jill, fr√®re et s≈ìur, partent en qu√™te d'eau mais rencontrent un malheur sur le chemin.\n",
      "\n",
      "Names: Jack, Jill\n",
      "\n",
      "Output JSON: \n",
      "{\n",
      "  \"french_summary\": \"Jack et Jill, fr√®re et s≈ìur, partent en qu√™te d'eau mais rencontrent un malheur sur le chemin.\",\n",
      "  \"num_names\": 2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# example 1: Give it time to think\n",
    "text = f\"\"\"\n",
    "In a charming village, siblings Jack and Jill set out on \\ \n",
    "a quest to fetch water from a hilltop \\ \n",
    "well. As they climbed, singing joyfully, misfortune \\ \n",
    "struck‚ÄîJack tripped on a stone and tumbled \\ \n",
    "down the hill, with Jill following suit. \\ \n",
    "Though slightly battered, the pair returned home to \\ \n",
    "comforting embraces. Despite the mishap, \\ \n",
    "their adventurous spirits remained undimmed, and they \\ \n",
    "continued exploring with delight.\n",
    "\"\"\"\n",
    "\n",
    "prompt1 = f\"\"\"\n",
    "Perform the following actions: \n",
    "1 - Summarize text delimited by triple asterisks, in one SHORT sentence \\\n",
    "2 - Translate summary into Spanish.\n",
    "3 - List each name in the Spanish summary.\n",
    "4 - Output a json object that contains the following \\\n",
    "keys: spanish_summary, num_names.\n",
    "\n",
    "Separate answers for each step with \"----\" lines.\n",
    "\n",
    "Text:\n",
    "***{text}***\n",
    "\"\"\"\n",
    "print(\"Completion 1:\")\n",
    "print(get_completion(prompt1))\n",
    "\n",
    "# example 2: Specify Format\n",
    "prompt2 = f\"\"\"\n",
    "Your task is to perform the following actions: \n",
    "1 - Summarize the following text delimited by \n",
    "  <> with 1 sentence.\n",
    "2 - Translate the summary into French.\n",
    "3 - List each name in the French summary.\n",
    "4 - Output a json object that contains the \n",
    "  following keys: french_summary, num_names.\n",
    "\n",
    "Use the following format:\n",
    "Text: <text to summarize>\n",
    "Summary: <summary>\n",
    "Translation: <summary translation>\n",
    "Names: <list of names in summary>\n",
    "Output JSON: <json with summary and num_names>\n",
    "\n",
    "Text: <{text}>\n",
    "\"\"\"\n",
    "print(\"Completion 2:\")\n",
    "print(get_completion(prompt2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Tactic: Instruct Model To Work it out (chain of thought)\n",
    "\n",
    "Instead of telling model what to do (give it a chain of reasoning) ask it to tell us how it would solve the problem (chain of thought). This slows model down and makes it think before rushing to a conclusion (otherwise it may get the wrong response). Try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick Response:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The student's solution is correct. The total cost for the first year of operations as a function of the number of square feet is indeed 450x + 100,000.\n",
      "-------------------\n",
      "Measured Response:\n",
      "Let x be the size of the installation in square feet.\n",
      "\n",
      "Costs:\n",
      "1. Land cost: $100 * x\n",
      "2. Solar panel cost: $250 * x\n",
      "3. Maintenance cost: $100,000 + $10 * x\n",
      "\n",
      "Total cost: $100 * x + $250 * x + $100,000 + $10 * x = $360 * x + $100,000\n",
      "\n",
      "The total cost for the first year of operations as a function of the number of square feet is $360x + $100,000.\n",
      "```\n",
      "\n",
      "Is the student's solution the same as actual solution just calculated:\n",
      "```\n",
      "No\n",
      "```\n",
      "\n",
      "Student grade:\n",
      "```\n",
      "incorrect\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "problem = f\"\"\"\n",
    "Question:\n",
    "```\n",
    "I'm building a solar power installation and I need \\\n",
    " help working out the financials. \n",
    "- Land costs $100 / square foot\n",
    "- I can buy solar panels for $250 / square foot\n",
    "- I negotiated a contract for maintenance that will cost \\ \n",
    "me a flat $100k per year, and an additional $10 / square \\\n",
    "foot\n",
    "What is the total cost for the first year of operations \n",
    "as a function of the number of square feet.\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "student_solution = \"\"\"\n",
    "Student's Solution:\n",
    "```\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Land cost: 100x\n",
    "2. Solar panel cost: 250x\n",
    "3. Maintenance cost: 100,000 + 100x\n",
    "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "prompt1 = f\"\"\"\n",
    "Determine if the student's solution is correct or not.\n",
    "{problem}\n",
    "{student_solution}\n",
    "\"\"\"\n",
    "\n",
    "prompt2= f\"\"\"\n",
    "Your task is to determine if the student's solution \\\n",
    "is correct or not.\n",
    "To solve the problem do the following:\n",
    "- First, work out your own solution to the problem including the final total. \n",
    "- Then compare your solution to the student's solution \\ \n",
    "and evaluate if the student's solution is correct or not. \n",
    "Don't decide if the student's solution is correct until \n",
    "you have done the problem yourself.\n",
    "\n",
    "Use the following format:\n",
    "Question:\n",
    "```\n",
    "question here\n",
    "```\n",
    "Student's solution:\n",
    "```\n",
    "student's solution here\n",
    "```\n",
    "Actual solution:\n",
    "```\n",
    "steps to work out the solution and your solution here\n",
    "```\n",
    "Is the student's solution the same as actual solution \\\n",
    "just calculated:\n",
    "```\n",
    "yes or no\n",
    "```\n",
    "Student grade:\n",
    "```\n",
    "correct or incorrect\n",
    "```\n",
    "{problem}\n",
    "{student_solution}\n",
    "Actual solution:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# example 1: No chain of thought\n",
    "print(\"Quick Response:\")\n",
    "print(get_completion(prompt1))\n",
    "\n",
    "# example 2: No chain of thought\n",
    "print(\"-------------------\")\n",
    "print(\"Measured Response:\")\n",
    "print(get_completion(prompt2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Model Limitations: Hallucinations\n",
    "\n",
    "Fabricated information that the model believes to be true. This can happen when the model is asked to generate information that is not in the training data - and it confabulates an answer. It makes responds sound plausible. One way to reduce this is to ask the model to find relevant information in the text and answer questions based on the extracted concepts and find citable references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AeroGlide UltraSlim Smart Toothbrush by Boie is a high-tech toothbrush designed to provide a superior cleaning experience. It features ultra-thin bristles that are gentle on the gums and teeth, while still effectively removing plaque and debris. The toothbrush also has a built-in timer and pressure sensor to help ensure you are brushing for the recommended two minutes and not applying too much pressure.\n",
      "\n",
      "The smart toothbrush connects to a mobile app via Bluetooth, allowing you to track your brushing habits and receive personalized recommendations for improving your oral hygiene routine. The app also provides reminders to replace your brush head when it is time for a new one.\n",
      "\n",
      "The AeroGlide UltraSlim Smart Toothbrush is made with antimicrobial materials to prevent bacteria growth and is designed to be long-lasting and environmentally friendly. It is rechargeable and comes with a sleek charging dock for easy storage and charging. Overall, this toothbrush offers a modern and effective solution for maintaining optimal oral health.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Tell me about AeroGlide UltraSlim Smart Toothbrush by Boie\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4. Iterative Prompt Development\n",
    "\n",
    "Prompt Engineering is more art than science. Similar to data science (MLOps) lifecycles, we have { idea generation, implementation, evaluation } cycles of iterative development. \n",
    "\n",
    "The Prompt Engineering process is now:\n",
    " - Try something => write a prompt to get a task done\n",
    " - Evaluate response => check if response is what you wanted with a sample input\n",
    " - Iterate prompt => analyze why response was flawed and clarify task in prompt\n",
    " - Repeat evaluate/iterate cycle => get prompt to acceptable state with ONE sample\n",
    " - Extend evaluate/iterate cycle => repeat this with more examples to refine prompt for fairness and consistency\n",
    "\n",
    "The key is to have a an **evaluation** process to let us see if changes we make to the prompt are having desired changes to completion quality. \n",
    " - Evaluation can start as a manual interactive process then move towards more evaluation at scale\n",
    " - First = manual evaluation with one target example => iterate till prompt gives me desired response for that example üëâüèΩ analogy = teacher grades a student paper (defines grading rubric)\n",
    " - Next = manual evaluation with more target examples => check if refined prompt works with broader set of examples üëâüèΩ analogy = teacher grades full class papers (refines grading rubric)\n",
    " - Next = AI-assisted evaluation with more examples => train another AI to check the responses for you üëâüèΩ analogy = teacher asks TA to grade class paper (provides grading rubric)\n",
    " - Next = AI-assisted evaluation at scale => use AI to evaluate responses at scale in CI/CD pipelines üëâüèΩ analogy = school asks TA org to grade all papers for all teachers  (provides grading rubric for all exams)\n",
    "\n",
    "Responsible AI now means we need to make sure teacher and rubric were fair (unbiased) and TA/Org were consistent and accountable in grading with the rubric.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1 Create Initial Prompt (Retail Catalog)\n",
    "\n",
    "\"Generate a marketing product description from a fact sheet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catalog Item\n",
    "fact_sheet_chair = \"\"\"\n",
    "OVERVIEW\n",
    "- Part of a beautiful family of mid-century inspired office furniture, \n",
    "including filing cabinets, desks, bookcases, meeting tables, and more.\n",
    "- Several options of shell color and base finishes.\n",
    "- Available with plastic back and front upholstery (SWC-100) \n",
    "or full upholstery (SWC-110) in 10 fabric and 6 leather options.\n",
    "- Base finish options are: stainless steel, matte black, \n",
    "gloss white, or chrome.\n",
    "- Chair is available with or without armrests.\n",
    "- Suitable for home or business settings.\n",
    "- Qualified for contract use.\n",
    "\n",
    "CONSTRUCTION\n",
    "- 5-wheel plastic coated aluminum base.\n",
    "- Pneumatic chair adjust for easy raise/lower action.\n",
    "\n",
    "DIMENSIONS\n",
    "- WIDTH 53 CM | 20.87‚Äù\n",
    "- DEPTH 51 CM | 20.08‚Äù\n",
    "- HEIGHT 80 CM | 31.50‚Äù\n",
    "- SEAT HEIGHT 44 CM | 17.32‚Äù\n",
    "- SEAT DEPTH 41 CM | 16.14‚Äù\n",
    "\n",
    "OPTIONS\n",
    "- Soft or hard-floor caster options.\n",
    "- Two choices of seat foam densities: \n",
    " medium (1.8 lb/ft3) or high (2.8 lb/ft3)\n",
    "- Armless or 8 position PU armrests \n",
    "\n",
    "MATERIALS\n",
    "SHELL BASE GLIDER\n",
    "- Cast Aluminum with modified nylon PA6/PA66 coating.\n",
    "- Shell thickness: 10 mm.\n",
    "SEAT\n",
    "- HD36 foam\n",
    "\n",
    "COUNTRY OF ORIGIN\n",
    "- Italy\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introducing our stylish and versatile mid-century inspired office chair, perfect for both home and business settings. This chair is part of a beautiful family of office furniture that includes filing cabinets, desks, bookcases, meeting tables, and more.\n",
      "\n",
      "Customize your chair with several options of shell color and base finishes to suit your personal style. Choose between plastic back and front upholstery or full upholstery in a variety of fabric and leather options. The base finish options include stainless steel, matte black, gloss white, or chrome. You can also choose to have armrests or go for a sleek armless design.\n",
      "\n",
      "Constructed with a 5-wheel plastic coated aluminum base and featuring a pneumatic chair adjust for easy raise/lower action, this chair is both durable and functional. The dimensions of the chair are as follows: width 53 cm, depth 51 cm, height 80 cm, seat height 44 cm, and seat depth 41 cm.\n",
      "\n",
      "Personalize your chair even further with options such as soft or hard-floor caster options, two choices of seat foam densities (medium or high), and armless or 8 position PU armrests.\n",
      "\n",
      "Made with high-quality materials including cast aluminum with modified nylon coating for the shell base glider and HD36 foam for the seat, this chair is designed to provide comfort and style. Plus, it is qualified for contract use, making it a reliable choice for any workspace.\n",
      "\n",
      "Add a touch of Italian craftsmanship to your office with our mid-century inspired office chair. Elevate your workspace with this elegant and functional piece of furniture.\n"
     ]
    }
   ],
   "source": [
    "# Initial Prompt\n",
    "prompt = f\"\"\"\n",
    "Your task is to help a marketing team create a \n",
    "description for a retail website of a product based \n",
    "on a technical fact sheet.\n",
    "\n",
    "Write a product description based on the information \n",
    "provided in the technical specifications delimited by \n",
    "triple backticks.\n",
    "\n",
    "Technical specifications: ```{fact_sheet_chair}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2 Refine Initial Prompt (Response Length)\n",
    "\"Issue: The text was too long. Let's adjust that\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introducing our versatile and stylish mid-century office chair, available in a variety of colors and finishes to suit any space. With adjustable height and comfortable upholstery options, this chair is perfect for both home and business use. Made with quality materials from Italy, this chair is built to last.\n"
     ]
    }
   ],
   "source": [
    "# Refined Prompt\n",
    "prompt = f\"\"\"\n",
    "Your task is to help a marketing team create a \n",
    "description for a retail website of a product based \n",
    "on a technical fact sheet.\n",
    "\n",
    "Write a product description based on the information \n",
    "provided in the technical specifications delimited by \n",
    "triple backticks.\n",
    "\n",
    "USE AT MOST 50 WORDS\n",
    "\n",
    "Technical specifications: ```{fact_sheet_chair}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3 Refine Iterated Prompt (Response Quality)\n",
    "\n",
    "\"Issue: The text missed key details. Let's correct that\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introducing our versatile and stylish office chair, part of a mid-century inspired furniture collection. Choose from a variety of shell colors and base finishes to suit your space. Constructed with a durable aluminum base and high-density foam seat for comfort. Perfect for home or business use. \n",
      "\n",
      "Product IDs: SWC-100, SWC-110\n"
     ]
    }
   ],
   "source": [
    "# Refine Prompt\n",
    "# Add request to refine focus for response\n",
    "prompt = f\"\"\"\n",
    "Your task is to help a marketing team create a \n",
    "description for a retail website of a product based \n",
    "on a technical fact sheet.\n",
    "\n",
    "Write a product description based on the information \n",
    "provided in the technical specifications delimited by \n",
    "triple backticks.\n",
    "\n",
    "The description is intended for furniture retailers, \n",
    "so should be technical in nature and focus on the \n",
    "materials the product is constructed from.\n",
    "\n",
    "At the end of the description, include every 7-character \n",
    "Product ID in the technical specification.\n",
    "\n",
    "Use at most 50 words.\n",
    "\n",
    "Technical specifications: ```{fact_sheet_chair}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4 Refine Iterated Prompt (Response Format)\n",
    "\n",
    "\"Isse: I need this in HTML format for web page. Let's fix that\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```html\n",
      "<div>\n",
      "    <p>This mid-century inspired office chair is a stylish and versatile addition to any workspace. Constructed with a durable 5-wheel plastic coated aluminum base, this chair offers both style and functionality. The seat is made with high-density HD36 foam for maximum comfort and support. The chair is available in a variety of shell colors and base finishes to suit any decor. Whether for home or business use, this chair is a perfect choice for any setting.</p>\n",
      "    \n",
      "    <p>Product IDs: SWC-100, SWC-110</p>\n",
      "    \n",
      "    <h2>Product Dimensions</h2>\n",
      "    <table>\n",
      "        <tr>\n",
      "            <td>WIDTH</td>\n",
      "            <td>20.87\"</td>\n",
      "        </tr>\n",
      "        <tr>\n",
      "            <td>DEPTH</td>\n",
      "            <td>20.08\"</td>\n",
      "        </tr>\n",
      "        <tr>\n",
      "            <td>HEIGHT</td>\n",
      "            <td>31.50\"</td>\n",
      "        </tr>\n",
      "        <tr>\n",
      "            <td>SEAT HEIGHT</td>\n",
      "            <td>17.32\"</td>\n",
      "        </tr>\n",
      "        <tr>\n",
      "            <td>SEAT DEPTH</td>\n",
      "            <td>16.14\"</td>\n",
      "        </tr>\n",
      "    </table>\n",
      "</div>\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Refine Prompt\n",
    "# Get the description to add specific section with details in a table\n",
    "prompt = f\"\"\"\n",
    "Your task is to help a marketing team create a \n",
    "description for a retail website of a product based \n",
    "on a technical fact sheet.\n",
    "\n",
    "Write a product description based on the information \n",
    "provided in the technical specifications delimited by \n",
    "triple backticks.\n",
    "\n",
    "The description is intended for furniture retailers, \n",
    "so should be technical in nature and focus on the \n",
    "materials the product is constructed from.\n",
    "\n",
    "At the end of the description, include every 7-character \n",
    "Product ID in the technical specification.\n",
    "\n",
    "After the description, include a table that gives the \n",
    "product's dimensions. The table should have two columns.\n",
    "In the first column include the name of the dimension. \n",
    "In the second column include the measurements in inches only.\n",
    "\n",
    "Give the table the title 'Product Dimensions'.\n",
    "\n",
    "Format everything as HTML that can be used in a website. \n",
    "Place the description in a <div> element.\n",
    "\n",
    "Technical specifications: ```{fact_sheet_chair}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "```html\n",
       "<div>\n",
       "    <p>This mid-century inspired office chair is a stylish and versatile addition to any workspace. Constructed with a durable 5-wheel plastic coated aluminum base, this chair offers both style and functionality. The seat is made with high-density HD36 foam for maximum comfort and support. The chair is available in a variety of shell colors and base finishes to suit any decor. Whether for home or business use, this chair is a perfect choice for any setting.</p>\n",
       "    \n",
       "    <p>Product IDs: SWC-100, SWC-110</p>\n",
       "    \n",
       "    <h2>Product Dimensions</h2>\n",
       "    <table>\n",
       "        <tr>\n",
       "            <td>WIDTH</td>\n",
       "            <td>20.87\"</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>DEPTH</td>\n",
       "            <td>20.08\"</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>HEIGHT</td>\n",
       "            <td>31.50\"</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>SEAT HEIGHT</td>\n",
       "            <td>17.32\"</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>SEAT DEPTH</td>\n",
       "            <td>16.14\"</td>\n",
       "        </tr>\n",
       "    </table>\n",
       "</div>\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hard to review the markdown manually - let's use the code cell to format it the way the web page would render it\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks good - let's ship it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 5. Summarizing\n",
    "\n",
    "This exercise explores how prompts can be engineered to improve the quality of a **summarization task** that takes a large volume of text (\"primary content\") and has the model generate a concise summary of the content (\"response\") by providing the relevant instructions (\"prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary Content: Single Product Review\n",
    "prod_review = \"\"\"\n",
    "Got this panda plush toy for my daughter's birthday, \\\n",
    "who loves it and takes it everywhere. It's soft and \\ \n",
    "super cute, and its face has a friendly look. It's \\ \n",
    "a bit small for what I paid though. I think there \\ \n",
    "might be other options that are bigger for the \\ \n",
    "same price. It arrived a day earlier than expected, \\ \n",
    "so I got to play with it myself before I gave it \\ \n",
    "to her.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1 First Prompt: Summarize Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: \n",
      "The panda plush toy is soft, cute, and has a friendly face, making it a hit with the reviewer's daughter. However, the reviewer feels that it is a bit small for the price paid and suggests that there may be larger options available for the same price. Despite this, the reviewer was pleased with the early delivery and had the chance to enjoy the toy before giving it to their daughter.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review from an ecommerce site. \n",
    "\n",
    "Summarize the review below, delimited by triple \n",
    "backticks \n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Refine Prompt: Specify Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "Cute panda plush toy loved by daughter, soft and friendly-looking. Smaller than expected for the price, but arrived early.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review from an ecommerce site. \n",
    "\n",
    "Summarize the review below, delimited by triple \n",
    "backticks, in at most 30 words. \n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Refine Prompt: Create Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: \"Cute panda plush toy, soft and loved by daughter. Small for price, but arrived early.\"\n",
      "\n",
      "Spanish: \"Peluche de panda lindo, suave y amado por mi hija. Peque√±o para el precio, pero lleg√≥ temprano.\"\n",
      "French: \"Peluche panda mignon, doux et aim√© par ma fille. Petit pour le prix, mais est arriv√© t√¥t.\"\n",
      "Italian: \"Peluche panda carino, morbido e amato da mia figlia. Piccolo per il prezzo, ma √® arrivato presto.\"\n",
      "German: \"Niedliches Panda-Pl√ºschtier, weich und von meiner Tochter geliebt. Klein f√ºr den Preis, aber kam fr√ºh an.\"\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review from an ecommerce site. \n",
    "\n",
    "Summarize the review below, delimited by triple \n",
    "backticks, in at most 30 words. \n",
    "\n",
    "Then translate that review into Spanish, French, Italian and German.\n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Refine Prompt: Refine Focus On Shipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English:\n",
      "\"The panda plush toy arrived a day earlier than expected. It's soft, cute, and my daughter loves it. However, it's a bit small for the price.\"\n",
      "\n",
      "Spanish:\n",
      "\"El peluche de panda lleg√≥ un d√≠a antes de lo esperado. Es suave, lindo y a mi hija le encanta. Sin embargo, es un poco peque√±o para el precio.\"\n",
      "\n",
      "French:\n",
      "\"Le jouet en peluche panda est arriv√© un jour plus t√¥t que pr√©vu. Il est doux, mignon et ma fille l'adore. Cependant, il est un peu petit pour le prix.\"\n",
      "\n",
      "Italian:\n",
      "\"Il peluche panda √® arrivato un giorno prima del previsto. √à morbido, carino e mia figlia lo adora. Tuttavia, √® un po' piccolo per il prezzo.\"\n",
      "\n",
      "German:\n",
      "\"Das Panda-Pl√ºschtier kam einen Tag fr√ºher als erwartet an. Es ist weich, niedlich und meine Tochter liebt es. Allerdings ist es etwas klein f√ºr den Preis.\"\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review from an ecommerce site to give feedback to the \\\n",
    "Shipping deparmtment. \n",
    "\n",
    "Summarize the review below, delimited by triple \n",
    "backticks, in at most 30 words, and focusing on any aspects \\\n",
    "that mention shipping and delivery of the product. \n",
    "\n",
    "Print the English review first.\n",
    "Then translate that review into Spanish, French, Italian and German.\n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5 Refine Prompt: Refine Focus On Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review from an ecommerce site to give feedback to the \\\n",
    "Shipping deparmtment. \n",
    "\n",
    "Summarize the review below, delimited by triple \n",
    "backticks, in at most 30 words,  and focusing on any aspects \\\n",
    "that are relevant to the price and perceived value. \n",
    "\n",
    "Print the English review first.\n",
    "Then translate that review into Spanish, French, Italian and German.\n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6 Refine Prompt: Use Extract not Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedback: The product arrived a day earlier than expected, allowing the customer to play with it before giving it as a gift.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to extract relevant information from \\ \n",
    "a product review from an ecommerce site to give \\\n",
    "feedback to the Shipping department. \n",
    "\n",
    "From the review below, delimited by triple quotes \\\n",
    "extract the information relevant to shipping and \\ \n",
    "delivery. Limit to 30 words. \n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.7 Refine Prompt: Validate with Multiple Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "review_1 = prod_review \n",
    "\n",
    "# review for a standing lamp\n",
    "review_2 = \"\"\"\n",
    "Needed a nice lamp for my bedroom, and this one \\\n",
    "had additional storage and not too high of a price \\\n",
    "point. Got it fast - arrived in 2 days. The string \\\n",
    "to the lamp broke during the transit and the company \\\n",
    "happily sent over a new one. Came within a few days \\\n",
    "as well. It was easy to put together. Then I had a \\\n",
    "missing part, so I contacted their support and they \\\n",
    "very quickly got me the missing piece! Seems to me \\\n",
    "to be a great company that cares about their customers \\\n",
    "and products. \n",
    "\"\"\"\n",
    "\n",
    "# review for an electric toothbrush\n",
    "review_3 = \"\"\"\n",
    "My dental hygienist recommended an electric toothbrush, \\\n",
    "which is why I got this. The battery life seems to be \\\n",
    "pretty impressive so far. After initial charging and \\\n",
    "leaving the charger plugged in for the first week to \\\n",
    "condition the battery, I've unplugged the charger and \\\n",
    "been using it for twice daily brushing for the last \\\n",
    "3 weeks all on the same charge. But the toothbrush head \\\n",
    "is too small. I‚Äôve seen baby toothbrushes bigger than \\\n",
    "this one. I wish the head was bigger with different \\\n",
    "length bristles to get between teeth better because \\\n",
    "this one doesn‚Äôt.  Overall if you can get this one \\\n",
    "around the $50 mark, it's a good deal. The manufactuer's \\\n",
    "replacements heads are pretty expensive, but you can \\\n",
    "get generic ones that're more reasonably priced. This \\\n",
    "toothbrush makes me feel like I've been to the dentist \\\n",
    "every day. My teeth feel sparkly clean! \n",
    "\"\"\"\n",
    "\n",
    "# review for a blender\n",
    "review_4 = \"\"\"\n",
    "So, they still had the 17 piece system on seasonal \\\n",
    "sale for around $49 in the month of November, about \\\n",
    "half off, but for some reason (call it price gouging) \\\n",
    "around the second week of December the prices all went \\\n",
    "up to about anywhere from between $70-$89 for the same \\\n",
    "system. And the 11 piece system went up around $10 or \\\n",
    "so in price also from the earlier sale price of $29. \\\n",
    "So it looks okay, but if you look at the base, the part \\\n",
    "where the blade locks into place doesn‚Äôt look as good \\\n",
    "as in previous editions from a few years ago, but I \\\n",
    "plan to be very gentle with it (example, I crush \\\n",
    "very hard items like beans, ice, rice, etc. in the \\ \n",
    "blender first then pulverize them in the serving size \\\n",
    "I want in the blender then switch to the whipping \\\n",
    "blade for a finer flour, and use the cross cutting blade \\\n",
    "first when making smoothies, then use the flat blade \\\n",
    "if I need them finer/less pulpy). Special tip when making \\\n",
    "smoothies, finely cut and freeze the fruits and \\\n",
    "vegetables (if using spinach-lightly stew soften the \\ \n",
    "spinach then freeze until ready for use-and if making \\\n",
    "sorbet, use a small to medium sized food processor) \\ \n",
    "that you plan to use that way you can avoid adding so \\\n",
    "much ice if at all-when making your smoothie. \\\n",
    "After about a year, the motor was making a funny noise. \\\n",
    "I called customer service but the warranty expired \\\n",
    "already, so I had to buy another one. FYI: The overall \\\n",
    "quality has gone done in these types of products, so \\\n",
    "they are kind of counting on brand recognition and \\\n",
    "consumer loyalty to maintain sales. Got it in about \\\n",
    "two days.\n",
    "\"\"\"\n",
    "\n",
    "reviews = [review_1, review_2, review_3, review_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Positive: Adorable panda plush toy, soft and cute. Small for price, but arrived early. \n",
      "\n",
      "1 Positive: Lamp with storage, fast delivery, excellent customer service, easy assembly, missing part quickly resolved. Great company. \n",
      "\n",
      "2 Positive: Impressive battery life, small head, good deal for $50, generic replacement heads available, teeth feel clean. \n",
      "\n",
      "3 Mixed: Price fluctuations, quality concerns, motor issues, and tips for usage. Brand loyalty emphasized. Delivery prompt. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(reviews)):\n",
    "    prompt = f\"\"\"\n",
    "    Your task is to generate a short summary of a product \\ \n",
    "    review from an ecommerce site. \n",
    "\n",
    "    Summarize the review below, delimited by triple \\\n",
    "    backticks in at most 20 words. \n",
    "\n",
    "    Start each summary with a single word that describes the core sentiment of the review.\n",
    "\n",
    "    Review: ```{reviews[i]}```\n",
    "    \"\"\"\n",
    "\n",
    "    response = get_completion(prompt)\n",
    "    print(i, response, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 6. Inferring\n",
    "\n",
    "Here the model takes input and does some processing to _infer information_ before it returns the response. The main difference is that I am replacing traditional \"machine learning\" (train model to do X) with \"generative AI\" (ask model to do X) using natural language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product review text (primary content)\n",
    "lamp_review = \"\"\"\n",
    "Needed a nice lamp for my bedroom, and this one had \\\n",
    "additional storage and not too high of a price point. \\\n",
    "Got it fast.  The string to our lamp broke during the \\\n",
    "transit and the company happily sent over a new one. \\\n",
    "Came within a few days as well. It was easy to put \\\n",
    "together.  I had a missing part, so I contacted their \\\n",
    "support and they very quickly got me the missing piece! \\\n",
    "Lumina seems to me to be a great company that cares \\\n",
    "about their customers and products!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 First Prompt: Infer sentiment for Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the product review is positive. The reviewer is satisfied with the lamp, the customer service, and the company in general.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "What is the sentiment of the following product review, \n",
    "which is delimited with triple backticks?\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Refine: Specify acceptable values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "What is the sentiment of the following product review, \n",
    "which is delimited with triple backticks?\n",
    "\n",
    "Give your answer as a single word, either \"positive\" \\\n",
    "or \"negative\".\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 Refine: Identify types of emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy, satisfied, grateful, impressed, content\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify a list of emotions that the writer of the \\\n",
    "following review is expressing. Include no more than \\\n",
    "five items in the list. Format your answer as a list of \\\n",
    "lower-case words separated by commas.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4 Refine: Look for specific emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\n",
      "Anger: No\n",
      "Joy: Yes\n",
      "Sadness: No\n",
      "Fear: No\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Is the writer of the following review expressing anger?\\\n",
    "The review is delimited with triple backticks. \\\n",
    "Give your answer as either yes or no.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Is the writer of the following review expressing anger, joy, sadness or fear?\\\n",
    "The review is delimited with triple backticks. \\\n",
    "Give your answer as either yes or no for each emotion.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5 Refine: Extract information with format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Item\": \"lamp\",\n",
      "  \"Brand\": \"Lumina\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text: \n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Item\" and \"Brand\" as the keys. \n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "Make your response as short as possible.\n",
    "  \n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.6 Refine: Do multiple tasks in one prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Sentiment\": \"positive\",\n",
      "    \"Anger\": false,\n",
      "    \"Item\": \"lamp\",\n",
      "    \"Brand\": \"Lumina\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text: \n",
    "- Sentiment (positive or negative)\n",
    "- Is the reviewer expressing anger? (true or false)\n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Sentiment\", \"Anger\", \"Item\" and \"Brand\" as the keys.\n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "Make your response as short as possible.\n",
    "Format the Anger value as a boolean.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.7 First Prompt: Infer Topics from Story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Story\n",
    "story = \"\"\"\n",
    "In a recent survey conducted by the government, \n",
    "public sector employees were asked to rate their level \n",
    "of satisfaction with the department they work at. \n",
    "The results revealed that NASA was the most popular \n",
    "department with a satisfaction rating of 95%.\n",
    "\n",
    "One NASA employee, John Smith, commented on the findings, \n",
    "stating, \"I'm not surprised that NASA came out on top. \n",
    "It's a great place to work with amazing people and \n",
    "incredible opportunities. I'm proud to be a part of \n",
    "such an innovative organization.\"\n",
    "\n",
    "The results were also welcomed by NASA's management team, \n",
    "with Director Tom Johnson stating, \"We are thrilled to \n",
    "hear that our employees are satisfied with their work at NASA. \n",
    "We have a talented and dedicated team who work tirelessly \n",
    "to achieve our goals, and it's fantastic to see that their \n",
    "hard work is paying off.\"\n",
    "\n",
    "The survey also revealed that the \n",
    "Social Security Administration had the lowest satisfaction \n",
    "rating, with only 45% of employees indicating they were \n",
    "satisfied with their job. The government has pledged to \n",
    "address the concerns raised by employees in the survey and \n",
    "work towards improving job satisfaction across all departments.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Survey\n",
      "2. Job satisfaction\n",
      "3. NASA\n",
      "4. Social Security Administration\n",
      "5. Government pledge\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine five topics that are being discussed in the \\\n",
    "following text, which is delimited by triple backticks.\n",
    "\n",
    "Make each item one or two words long. \n",
    "\n",
    "Format your response as a list of items SEPARATED BY COMMAS.\n",
    "\n",
    "Text sample: '''{story}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.8 Refine: Specify separator, enumeration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine five topics that are being discussed in the \\\n",
    "following text, which is delimited by triple backticks.\n",
    "\n",
    "Make each item one or two words long. \n",
    "\n",
    "Format your response as a list of items separated by commas.\n",
    "\n",
    "Text sample: '''{story}'''\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 7. Transforming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 8. Expanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 9. Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 10. Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
